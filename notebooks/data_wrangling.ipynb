{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cPickle as pickle\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot\n",
    "import sklearn as sk\n",
    "import os\n",
    "from osgeo import ogr\n",
    "import geopandas as gpd\n",
    "import operator\n",
    "import json\n",
    "from shapely.geometry import Point, shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel('../NIJ2013_JAN01_DEC31.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_uniques = []\n",
    "for i in df.columns:\n",
    "    col_uniques.append([df[i].unique(), i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filter(lambda x: x[1] == 'CASE DESC', col_uniques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[df['final_case_type'] == 'DISTP ']['CASE DESC'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in df.columns[:-4]:\n",
    "    df[i] = df[i].str.rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "excels = []\n",
    "e = os.listdir('../data/')\n",
    "for i in e:\n",
    "    if i.endswith('_Data'):\n",
    "        files = list(os.walk('../data/' + i))[0]\n",
    "        excel = filter(lambda x: x.endswith('.xlsx'), files[2])\n",
    "        excels.append(files[0] + '/' + excel[0])\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataframes = []\n",
    "for i in excels:\n",
    "    print 'reading %s' % i\n",
    "    dataframes.append(pd.read_excel(i))\n",
    "    print 'read %s' % i\n",
    "bigDF = pd.concat(dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bigDF.to_csv('../data/cleanData/all_crim_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "burg = bigDF[bigDF['CATEGORY'] == 'BURGLARY']\n",
    "burg_counts = burg[['CATEGORY', 'occ_date']].groupby('occ_date').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "burg_counts.resample('2Q', 'sum').plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#fig, ax = pyplot.subplots()\n",
    "#weekly_sample.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#driver = ogr.GetDriverByName('ESRI Shapefile')\n",
    "#gridfile = \"../data/shapefiles/testfinalclip.shp\"\n",
    "#gridSource = driver.Open(gridfile, 0) # 0 means read-only. 1 means writeable.\n",
    "#gridLayer = gridSource.GetLayer()\n",
    "#gridPoints = []\n",
    "#geoms = []\n",
    "#for feature in gridLayer:\n",
    "#    geom = feature.GetGeometryRef()\n",
    "#    geoms.append(geom)\n",
    "#    p = geom.GetEnvelope()\n",
    "#    print p\n",
    "#    gridPoints.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g1 = gpd.GeoDataFrame.from_file(\"../data/shapefiles/Portland_Police_Districts.shp\")\n",
    "g2 = gpd.GeoDataFrame.from_file(\"../data/shapefiles/polyGrid.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g1 = gpd.GeoDataFrame.from_file(\"../data/shapefiles/Portland_Police_Districts.shp\")\n",
    "g2 = gpd.GeoDataFrame.from_file(\"../data/shapefiles/polyGrid.shp\")data = []\n",
    "for index, dist in g1.iterrows():\n",
    "    for index2, grid in g2.iterrows():\n",
    "        if dist['geometry'].intersects(grid['geometry']):\n",
    "            data.append({'geometry': dist['geometry'].intersection(grid['geometry']), 'district':dist['DISTRICT'], \n",
    "                         'precinct': dist['PRECINCT']})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['geometry', 'precinct', 'district']"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "geoDF = gpd.GeoDataFrame(data, columns=['district', 'geometry', 'precinct'])\n",
    "geoDF.to_file('../data/shapefiles/intersections.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "squares = []\n",
    "for i in range(len(bigDF)):\n",
    "    if i % 10000 == 0:\n",
    "        print 'on row %d, %d percent complete' % (i, float(i)/len(bigDF))\n",
    "    coord = bigDF.iloc[i][['x_coordinate', 'y_coordinate']]\n",
    "    pt = Point(coord['x_coordinate'], coord['y_coordinate'])\n",
    "    g = geoDF[geoDF.geometry.contains(pt) == True]['geometry']\n",
    "    squares.append({'df_index':i, 'square_index': g.index.values[0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data = []\n",
    "#for i in range(len(g1)):\n",
    "#    print i\n",
    "#    for y in range(len(g3)):\n",
    "#        if y % 1000 == 0:\n",
    "#            print y\n",
    "#        if g1.iloc[i]['geometry'].intersects(g2.iloc[y]['geometry']):\n",
    "#            data.append({'geometry': g1.iloc[i]['geometry'].intersection(g2.iloc[y]['geometry']), 'district':g1.iloc[i]['DISTRICT'], \n",
    "#                       'precinct': g1.iloc[i]['PRECINCT']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coord = bigDF.iloc[-1][['x_coordinate', 'y_coordinate']]\n",
    "pt = Point(coord['x_coordinate'], coord['y_coordinate'])\n",
    "g = geoDF[geoDF.geometry.contains(pt) == True]['geometry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bigDF[926740:926744]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sq = filter(lambda x: len(x) != 0, squares)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sq[0].index.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ldf = bigDF[10:20]\n",
    "ldf.iloc[9][['x_coordinate', 'y_coordinate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sq = pickle.load(open('../data/cleanData/testmatched.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GEO_DF_PATH = \"../data/shapefiles/intersections.shp\"\n",
    "\n",
    "def matchPoints(bigDF):\n",
    "    geoDF =  gpd.GeoDataFrame.from_file(GEO_DF_PATH)\n",
    "    squares = []\n",
    "    for i in range(len(bigDF)):\n",
    "        if i % 10000 == 0:\n",
    "            print 'on row %d, %f percent complete' % (i, float(i)/float(len(bigDF)))\n",
    "        coord = bigDF.iloc[i][['x_coordinate', 'y_coordinate']]\n",
    "        pt = Point(coord['x_coordinate'], coord['y_coordinate'])\n",
    "        g = geoDF[geoDF.geometry.contains(pt) == True]['geometry']\n",
    "        if len(g) > 0:\n",
    "            squares.append({'df_index':i, 'square_index': g.index.values[0]})\n",
    "        else:\n",
    "            squares.append({'df_index':i, 'square_index': None})\n",
    "        print 'COMPLETED %d rows, %f percent complete' % (i+1, float(i+1)/float(len(bigDF)))\n",
    "    return squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'reading pdf'\n",
    "#pdf = pd.read_csv('../data/cleanData/all_crim_data.csv')\n",
    "chunk_size = 2\n",
    "splits = range(0, len(bigDF), chunk_size)\n",
    "#chunks = map(lambda x: x + chunk_size, splits)\n",
    "print 'splitting df'\n",
    "df_list = map(lambda x: bigDF[x:x+chunk_size], splits)\n",
    "print 'starting matching process'\n",
    "res = map(lambda x: matchPoints(x), df_list[:2])\n",
    "print 'completed match'\n",
    "matched = reduce(operator.add, res)\n",
    "pklPath = '../data/cleanData/testmatched.pkl'\n",
    "print 'saving %d matches in %s' % (len(matched), pklPath)\n",
    "#pickle.dump(matched, open(pklPath, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = map(lambda x: matchPoints(x), df_list[:2])\n",
    "print 'completed match'\n",
    "matched = reduce(operator.add, res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matched = reduce(operator.add, res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "json.dump(matched, open('testmatched.json', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "json.load(open('testmatched.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(bigDF)/13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = range(5)\n",
    "reduce(operator.add, l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "def useThis(f):\n",
    "    print f(range(5))\n",
    "useThis(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g1 = gpd.GeoDataFrame.from_file(\"../data/shapefiles/Portland_Police_Districts.shp\")\n",
    "g2 = gpd.GeoDataFrame.from_file(\"../data/shapefiles/polyGrid.shp\")\n",
    "data = []\n",
    "for i in range(len(g1)):\n",
    "    print i\n",
    "    for y in range(len(g3)):\n",
    "        if y % 1000 == 0:\n",
    "            print y\n",
    "        if g1.iloc[i]['geometry'].intersects(g2.iloc[y]['geometry']):\n",
    "            data.append({'geometry': g1.iloc[i]['geometry'].intersection(g2.iloc[y]['geometry']), \n",
    "                         'district':g1.iloc[i]['DISTRICT'], \n",
    "                       'precinct': g1.iloc[i]['PRECINCT']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(g1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a.'"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'a.shp'[:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
